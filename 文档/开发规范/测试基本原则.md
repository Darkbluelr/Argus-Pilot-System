# 测试基本原则

## 1. 引言

软件测试是保证 Argus Pilot System 项目质量、稳定性和可维护性的关键环节。本文档概述了本项目进行软件测试的基本原则和策略。所有开发者（包括 AI 助手）在编写代码时都应考虑其可测试性，并按要求编写和维护测试用例。

## 2. 测试目标

*   **验证功能正确性:** 确保代码按预期工作，满足需求文档 (`文档/项目核心信息/核心需求概述.md`) 的要求。
*   **防止回归 (Regression Prevention):** 确保新的更改没有破坏现有功能。
*   **改进设计:** 编写测试的过程有助于发现代码设计中的问题（如高耦合、难以依赖注入）。
*   **提供文档:** 测试用例本身可以作为代码使用方式的示例。
*   **支持重构:** 良好的测试覆盖率为安全的重构提供了信心。

## 3. 测试类型概述

本项目主要关注以下类型的自动化测试：

*   **单元测试 (Unit Tests):**
    *   **目标:** 测试最小的可测试单元（通常是函数、方法或类），隔离其依赖。
    *   **特点:** 运行速度快，数量最多。
    *   **要求:** **核心引擎逻辑 (`src/argus_pilot/core/`)、适配器管理器 (`src/argus_pilot/adapters/manager.py`)、通用工具函数 (`src/argus_pilot/common/`) 必须有高覆盖率的单元测试。** 复杂的适配器逻辑也应有单元测试覆盖。AI 生成的代码，特别是处理边界条件或复杂逻辑的部分，必须生成相应的单元测试。
    *   **工具:** **Pytest** (推荐，结合 `pytest-cov` 进行覆盖率统计)。
*   **集成测试 (Integration Tests):**
    *   **目标:** 测试核心引擎与适配器管理器、适配器接口的交互；测试适配器与模拟的应用程序环境（或真实应用的最小化实例）的交互。
    *   **特点:** 运行速度慢于单元测试，用于验证关键组件间的协作。
    *   **要求:** **核心的感知-认知-行动流程、适配器加载与调用流程、基本适配器功能（如 `click`, `type_text` 的通用逻辑）应有集成测试覆盖。**
    *   **工具:** **Pytest** (利用其 fixture 功能管理测试环境和依赖)。
*   **(可选) 端到端测试 (End-to-End / E2E Tests):**
    *   **目标:** 测试框架驱动一个或多个真实或模拟的应用程序完成一个完整的用户任务。
    *   **特点:** 运行最慢，设置复杂，但最能反映实际用户价值。
    *   **要求:** (初期可选) 覆盖 1-2 个核心的跨应用自动化场景。
    *   **工具:** 可能需要结合 Pytest 和特定的 GUI 自动化库 (如 `pyautogui`, `pywinauto` - 取决于目标平台) 或 Web 自动化库 (如 `Selenium`, `Playwright`)，以及用于启动和控制目标应用的脚本。

**测试侧重:** 本项目初期以**单元测试**为基础，确保核心逻辑和组件的正确性；辅以关键接口和流程的**集成测试**。E2E 测试根据项目进展和资源情况逐步添加。

## 4. 测试策略与原则

*   **测试先行 (Test-Driven Development - TDD) (可选但推荐):** 鼓励在开发新功能或修复 Bug 时尝试 TDD。
*   **可测试性设计 (Design for Testability):**
    *   编写的代码应易于测试。遵循**单一职责原则 (SRP)**。
    *   大量使用**依赖注入 (Dependency Injection)**，特别是对于核心引擎和适配器之间的交互，方便在测试中传入 Mock 对象或测试替身。
    *   避免在核心逻辑中直接创建难以控制的外部依赖（如直接调用系统 API 或 GUI 库的特定实现）。将这些交互封装在适配器中。
    *   函数应尽可能**纯粹 (Pure)**。
*   **测试覆盖率 (Code Coverage):**
    *   使用 `pytest-cov` (集成在 Pytest 中) 来衡量测试覆盖程度。
    *   **目标:** **`src/argus_pilot/core/` 和 `src/argus_pilot/common/` 模块力争达到 90% 以上的分支覆盖率。`src/argus_pilot/adapters/` (通用部分) 和 `src/argus_pilot/knowledge/` 模块力争达到 80% 以上分支覆盖率。** 适配器具体实现的覆盖率根据其复杂度和重要性决定。覆盖率是重要的参考指标，但不代表全部质量。
    *   覆盖率报告应用于识别未测试的代码区域。
*   **测试的 FIRST 原则:**
    *   **Fast (快速):** 单元测试必须快速。集成测试和 E2E 测试允许相对较慢，但应优化执行效率。
    *   **Independent/Isolated (独立/隔离):** 测试用例之间不应相互依赖。使用 Pytest 的 Fixture 来管理共享资源和状态隔离。
    *   **Repeatable (可重复):** 测试结果不应受执行顺序或外部环境（如日期时间、网络状态）影响。对于依赖外部状态的测试，使用 Mock 或固定数据。
    *   **Self-Validating (自我验证):** 测试必须包含明确的断言 (`assert`) 来自动判断成功或失败。
    *   **Timely (及时):** 测试代码必须与生产代码同步编写和维护。
*   **测试数据管理:**
    *   使用 Pytest Fixtures (`tests/fixtures/`) 来提供可复用的测试数据和对象。
    *   避免在测试代码中硬编码大量复杂数据。
*   **Mocking/Stubbing/Faking:**
    *   推荐使用 **`unittest.mock`** (Python 标准库) 或 **`pytest-mock`** (Pytest 插件) 来创建测试替身。
    *   重点 Mock 掉适配器与实际应用程序的交互部分（在单元测试和部分集成测试中），以及核心引擎的外部依赖（如 LMM 调用）。
    *   不应过度 Mock 内部实现细节。

## 5. 测试的组织与执行

*   **存放位置:** 测试代码必须存放在项目根目录下的 `tests/` 目录中，其内部结构应镜像源代码 (`src/`) 结构。
*   **命名约定:** 测试文件以 `test_` 开头 (例如 `test_engine.py`)。测试函数/方法以 `test_` 开头。
*   **自动化执行:**
    *   应在 `pyproject.toml` 中配置 `pytest` 作为测试运行器。
    *   提供便捷的命令 (例如通过 `Makefile` 或 `tox`) 运行所有测试、特定模块测试、生成覆盖率报告。
    *   **(如果配置了 CI)** 测试和代码覆盖率检查应在每次代码提交或 PR 时自动运行。PR 必须通过所有检查才能合并。

## 6. 何时编写/更新测试

*   **新功能开发:** 编写新代码时，必须同步编写相应的单元测试和（如果需要）集成测试。
*   **Bug 修复:** 在修复 Bug 之前，先编写一个能够复现该 Bug 的（失败的）测试用例。修复代码后，确保该测试用例通过，并保留该测试用例以防止回归。
*   **代码重构:** 在进行重构之前，确保相关代码有良好的测试覆盖。重构过程中，测试应始终保持通过。

## 7. AI 与测试

*   AI 助手应被指导生成可测试的代码，并遵循依赖注入等原则。
*   可以利用 AI 助手辅助生成单元测试的骨架，特别是针对核心逻辑和工具函数。
*   可以要求 AI 基于代码和需求文档分析并建议需要覆盖的测试场景（包括边界条件和异常情况）。
*   **AI 生成的测试代码必须经过人类开发者仔细审查和验证**，确保其断言的正确性、覆盖的有效性以及是否真正隔离了依赖。不能盲目接受 AI 生成的测试。
